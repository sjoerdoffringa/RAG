{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SjoerdO\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\rag--7y4UdRY-py3.13\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rag_module.rag import RAG\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class explainaRAG(RAG):\n",
    "    \"\"\"\n",
    "    This class extends the RAG class with explanation methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the explainaRAG instance with the provided arguments.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def is_in_scope(self, query, threshold=0.5):\n",
    "        n_chunks = self.embedder.index.ntotal\n",
    "        n_dims = self.embedder.dim\n",
    "        \n",
    "        document_vectors = np.zeros((n_chunks, n_dims), dtype=np.float32)\n",
    "        for i in range(n_chunks):\n",
    "            document_vectors[i] = self.embedder.index.reconstruct(i)\n",
    "        query_vector = self.embedder.encode(query).reshape(1, -1)\n",
    "        similarities = cosine_similarity(query_vector, document_vectors)\n",
    "        \n",
    "        max_sim = np.max(similarities)  # Highest similarity score\n",
    "        if max_sim > threshold:\n",
    "            return True, max_sim\n",
    "        else:\n",
    "            return False, max_sim\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default flashrank model for language en\n",
      "Default Model: ms-marco-MiniLM-L-12-v2\n",
      "Loading FlashRankRanker model ms-marco-MiniLM-L-12-v2 (this message can be suppressed by setting verbose=0)\n",
      "Loading model FlashRank model ms-marco-MiniLM-L-12-v2...\n"
     ]
    }
   ],
   "source": [
    "rag = explainaRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, np.float32(0.17998654))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "rag.is_in_scope(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In/Out scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Query: explainability in RAG systems.\n",
      " is OUT-OF-SCOPE (Max similarity: 0.33)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index_path = \"./embeddings/guidance_framework_2/chunk_vectors.faiss\"\n",
    "index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# Get stored document vectors\n",
    "num_docs = index.ntotal\n",
    "d = index.d  # Vector dimension\n",
    "document_vectors = np.zeros((num_docs, d), dtype=np.float32)\n",
    "for i in range(num_docs):\n",
    "    document_vectors[i] = index.reconstruct(i)\n",
    "\n",
    "# Load embedding model (use the same one used to create FAISS index)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed user query\n",
    "query_text = \"explainability in RAG systems.\"\n",
    "query_vector = model.encode(query_text).astype(np.float32).reshape(1, -1)\n",
    "\n",
    "# Search in FAISS (find nearest neighbors)\n",
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarities = cosine_similarity(query_vector, document_vectors)\n",
    "max_sim = np.max(similarities)  # Highest similarity score\n",
    "threshold = 0.5  # Define a threshold for \"in scope\"\n",
    "\n",
    "# Reduce dimensions for visualization using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(np.vstack([document_vectors, query_vector]))\n",
    "\n",
    "# Split transformed vectors\n",
    "docs_2d = reduced_vectors[:-1]  # Document embeddings\n",
    "query_2d = reduced_vectors[-1]   # Query embedding\n",
    "\n",
    "# Plot document space\n",
    "#plt.scatter(docs_2d[:, 0], docs_2d[:, 1], label=\"Documents\", alpha=0.5, s=5)\n",
    "#plt.scatter(query_2d[0], query_2d[1], color='orange', label=\"User Query\", s=20)\n",
    "\n",
    "# # Mark if query is out-of-scope\n",
    "# color = \"green\" if max_sim > threshold else \"red\"\n",
    "# plt.text(query_2d[0], query_2d[1], \"OUT-OF-SCOPE\" if max_sim < threshold else \"IN-SCOPE\", \n",
    "#          color=color, fontsize=12, ha='right')\n",
    "\n",
    "#plt.xlabel(\"Component 1\")\n",
    "#plt.ylabel(\"Component 2\")\n",
    "#plt.title(\"RAG Feature Space - Query vs Database\")\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "# Print results\n",
    "if max_sim > threshold:\n",
    "    print(f\"✅ Query: {query_text}\\n is IN-SCOPE (Max similarity: {max_sim:.2f})\")\n",
    "else:\n",
    "    print(f\"❌ Query: {query_text}\\n is OUT-OF-SCOPE (Max similarity: {max_sim:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag--7y4UdRY-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
